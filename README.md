![Kaggle Challenge](https://github.com/gleamingMushroom/Text-Analysis-Toxic-Comment-Classification/blob/master/kaggle%20image.png)

_[Solution to Featured Prediction Competition / Toxic Comment Classification Challenge on Kaggle](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)

# Machine Learning Project - Text Analysis - Toxic Comment Classification

> This is a text analysis project from Kaggle.
> Being provided with a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. The objective of this project is to create a model which predicts a probability of each type of toxicity for each comment. The types of toxicity are:

* toxic
* severe_toxic
* obscene
* threat
* insult
* identity_hate


### Data Description

> Datasets include a training set and a test set of labeled comments. 
* train.csv - the training set, contains comments with their binary labels.
* test.csv - the test set. 

### [Data Preprocessing & Model Development](https://github.com/gleamingMushroom/Text-Analysis-Toxic-Comment-Classification/blob/master/toxic%20comment%20classification%20presentation%20slides.pdf)  

### Python Coed: 
* [Jupyter Notebook 1](https://github.com/gleamingMushroom/Text-Analysis-Toxic-Comment-Classification/blob/master/Code%20Python.ipynb)
